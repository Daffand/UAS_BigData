{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmev2kAUXZoBNLA0oOGzyo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Daffand/UAS_BigData/blob/main/UAS_BDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uw0yZogJA4Rm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Environment:\n",
        "    def __init__(self):\n",
        "        self.grid_size = 5\n",
        "        self.goal = (4, 4)\n",
        "        self.hole = [(1, 1), (3, 3)]\n",
        "        self.actions = ['up', 'down', 'left', 'right']\n",
        "        self.state = (0, 0)\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = (0, 0)\n",
        "        return self.state\n",
        "\n",
        "    def step(self, action):\n",
        "        x, y = self.state\n",
        "\n",
        "        if action == 'up':\n",
        "            next_state = (x - 1, y) if x > 0 else (x, y)\n",
        "        elif action == 'down':\n",
        "            next_state = (x + 1, y) if x < self.grid_size - 1 else (x, y)\n",
        "        elif action == 'left':\n",
        "            next_state = (x, y - 1) if y > 0 else (x, y)\n",
        "        elif action == 'right':\n",
        "            next_state = (x, y + 1) if y < self.grid_size - 1 else (x, y)\n",
        "\n",
        "        if next_state == self.goal:\n",
        "            reward = 10\n",
        "        elif next_state in self.hole:\n",
        "            reward = -10\n",
        "        else:\n",
        "            reward = -1\n",
        "\n",
        "        self.state = next_state\n",
        "        return next_state, reward"
      ],
      "metadata": {
        "id": "RVgYkvJ2BZBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QLearningAgent:\n",
        "    def __init__(self, environment, learning_rate=0.1, discount_factor=0.9, epsilon=0.1):\n",
        "        self.environment = environment\n",
        "        self.learning_rate = learning_rate\n",
        "        self.discount_factor = discount_factor\n",
        "        self.epsilon = epsilon\n",
        "        self.q_table = np.zeros((environment.grid_size, environment.grid_size, len(environment.actions)))\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if random.uniform(0, 1) < self.epsilon:\n",
        "            return random.choice(self.environment.actions)\n",
        "        else:\n",
        "            action_values = self.q_table[state[0], state[1], :]\n",
        "            return self.environment.actions[np.argmax(action_values)]\n",
        "\n",
        "    def learn(self, state, action, next_state, reward):\n",
        "        current_q = self.q_table[state[0], state[1], self.environment.actions.index(action)]\n",
        "        max_future_q = np.max(self.q_table[next_state[0], next_state[1], :])\n",
        "        new_q = current_q + self.learning_rate * (reward + self.discount_factor * max_future_q - current_q)\n",
        "        self.q_table[state[0], state[1], self.environment.actions.index(action)] = new_q"
      ],
      "metadata": {
        "id": "eIPh_MM1BgAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat lingkungan dan agen\n",
        "env = Environment()\n",
        "agent = QLearningAgent(env)\n",
        "\n",
        "# Training\n",
        "num_episodes = 1000\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        action = agent.choose_action(state)\n",
        "        next_state, reward = env.step(action)\n",
        "        agent.learn(state, action, next_state, reward)\n",
        "        state = next_state\n",
        "\n",
        "        if state == env.goal or state in env.hole:\n",
        "            done = True\n",
        "\n",
        "# Pengujian\n",
        "state = env.reset()\n",
        "path = [state]\n",
        "\n",
        "while state != env.goal and state not in env.hole:\n",
        "    action = agent.choose_action(state)\n",
        "    next_state, _ = env.step(action)\n",
        "    state = next_state\n",
        "    path.append(state)\n",
        "\n",
        "if state == env.goal:\n",
        "    print(\"Goal reached!\")\n",
        "else:\n",
        "    print(\"Fell into hole.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nv2RWjV1BjI0",
        "outputId": "9af80faf-8876-4409-d496-fcc864cb24c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Goal reached!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Path taken:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVJKUVfuBltY",
        "outputId": "e1cd3048-7182-4555-9eb9-c0fb294a8f4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path taken: [(0, 0), (0, 1), (0, 2), (1, 2), (1, 3), (1, 4), (2, 4), (3, 4), (4, 4)]\n"
          ]
        }
      ]
    }
  ]
}